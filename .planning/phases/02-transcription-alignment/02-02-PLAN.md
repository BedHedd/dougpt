---
phase: 02-transcription-alignment
plan: 02
type: execute
wave: 2
depends_on:
  - 02-01
files_modified:
  - src/alignment/__init__.py
  - src/alignment/offset_detector.py
  - src/alignment/window_aligner.py
  - src/alignment/topic_matcher.py
  - src/alignment/models.py
  - src/pipeline/__init__.py
  - src/pipeline/phase2_runner.py
  - src/__init__.py
autonomous: true
requirements:
  - ALGN-02
user_setup: []

must_haves:
  truths:
    - "User can see per-VOD chat↔transcript offset estimates (auto-detected)"
    - "User can see aligned chat messages mapped to transcript windows"
    - "Alignment accounts for Twitch chat reaction lag (chat responds after Doug speaks)"
    - "Topic matching respects temporal proximity (nearby chat aligns to nearby transcript)"
    - "Alignment data stored in separate offset file (not inline in chat or transcript)"
    - "User can run QA hooks to verify alignment accuracy"
  artifacts:
    - path: "src/alignment/offset_detector.py"
      provides: "Auto offset detection via cross-correlation"
      exports: ["detect_chat_vod_offset"]
    - path: "src/alignment/window_aligner.py"
      provides: "Window-based chat-transcript alignment"
      exports: ["align_chat_to_transcript"]
    - path: "src/alignment/topic_matcher.py"
      provides: "Topic proximity constraints"
      exports: ["filter_by_topic_proximity"]
    - path: "src/alignment/models.py"
      provides: "Typed models for alignment data"
      exports: ["ChatMessage", "Alignment", "AlignmentResult"]
    - path: "src/pipeline/phase2_runner.py"
      provides: "CLI entry point for phase 2"
      exports: ["run_phase2"]
  key_links:
    - from: "src/alignment/offset_detector.py"
      to: "chat timestamps + transcript activity"
      via: "cross-correlation on histograms"
      pattern: "signal\\.correlate"
    - from: "src/alignment/window_aligner.py"
      to: "transcript segments + chat + offset"
      via: "reaction window matching"
      pattern: "reaction_window"
    - from: "src/pipeline/phase2_runner.py"
      to: "transcription + alignment modules"
      via: "orchestration"
      pattern: "transcribe_vod|detect_chat_vod_offset"
---

<objective>
Build chat-transcript alignment pipeline with auto offset detection and window-based matching.

Purpose: Enable automatic alignment of chat messages to transcript windows (ALGN-02), accounting for Twitch chat's natural reaction lag and temporal proximity constraints.

Output: Alignment module with offset detection, window-based alignment, topic proximity filtering, and CLI orchestration.
</objective>

<execution_context>
@/home/bedhedd/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/bedhedd/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-transcription-alignment/02-CONTEXT.md
@.planning/phases/02-transcription-alignment/02-RESEARCH.md
@.planning/phases/02-transcription-alignment/02-01-PLAN.md

# Codebase context
@.planning/codebase/STACK.md
@.planning/codebase/ARCHITECTURE.md
@.planning/codebase/CONVENTIONS.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create alignment data models</name>
  <files>src/alignment/__init__.py, src/alignment/models.py</files>
  <action>
Create typed data models for alignment data using pydantic.

In `src/alignment/models.py`:

```python
class ChatMessage(BaseModel):
    """A single chat message from Phase 1 ingestion."""
    timestamp: float  # seconds from VOD start
    text: str
    user: str
    badges: list[str] = []  # mod, sub, etc.

class Alignment(BaseModel):
    """A single chat-to-transcript alignment."""
    chat_msg: ChatMessage
    transcript_segment_id: int  # references TranscriptSegment.id
    offset: float  # chat_timestamp - transcript_start
    confidence: float  # 0.0 to 1.0
    reaction_lag: float  # how long after transcript the chat appeared

class AlignmentResult(BaseModel):
    """Full alignment output for a VOD."""
    vod_id: str
    global_offset: float  # detected chat-VOD offset
    alignments: list[Alignment]
    alignment_stats: dict  # avg_confidence, coverage, etc.
    config: dict  # window_size, proximity_threshold used
```

In `src/alignment/__init__.py`:
- Export: ChatMessage, Alignment, AlignmentResult
  </action>
  <verify>
`python -c "from src.alignment import ChatMessage, Alignment, AlignmentResult"` succeeds without error
  </verify>
  <done>
Alignment models importable and instantiate correctly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create offset detection algorithm</name>
  <files>src/alignment/offset_detector.py</files>
  <action>
Implement auto offset detection using cross-correlation on activity histograms.

Per CONTEXT.md locked decisions:
- Auto-detect offset automatically (not manual calibration)
- Per-VOD offset estimation

Per RESEARCH.md recommendations:
- Use cross-correlation on activity histograms
- Search range: -30 to +30 seconds
- Resolution: 0.5 second bins

Function signature:
```python
def detect_chat_vod_offset(
    chat_messages: list[ChatMessage],
    transcript_segments: list["TranscriptSegment"],  # from transcription module
    search_range: tuple[float, float] = (-30.0, 30.0),
    resolution: float = 0.5,
) -> float:
    """
    Auto-detect the offset between chat timestamps and transcript timestamps.
    
    Uses cross-correlation on activity histograms to find optimal offset.
    
    Returns: offset in seconds (add to transcript time to get chat time)
    """
```

Implementation from RESEARCH.md code example:
1. Build activity histogram for chat (message count per time bin)
2. Build activity histogram for transcript (speech duration per time bin)
3. Cross-correlate to find peak alignment
4. Return offset where correlation is highest within search range

Handle edge cases:
- Empty chat or transcript → return 0.0 with warning
- Very short VODs (< 60s) → reduce search range proportionally
  </action>
  <verify>
```bash
python -c "
from src.alignment.offset_detector import detect_chat_vod_offset
from src.alignment import ChatMessage
import inspect
sig = inspect.signature(detect_chat_vod_offset)
assert 'chat_messages' in sig.parameters
assert 'transcript_segments' in sig.parameters
print('Offset detector signature OK')
"
```
  </verify>
  <done>
detect_chat_vod_offset function exists, accepts chat and transcript data, returns float offset.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create window-based aligner with topic proximity</name>
  <files>src/alignment/window_aligner.py, src/alignment/topic_matcher.py</files>
  <action>
Implement window-based chat-transcript alignment with topic proximity constraints.

Per CONTEXT.md locked decisions:
- Window-based alignment — chat reacts to Doug with a delay
- Topic matching near timestamp — avoid matching distant chat
- Store alignment data in separate offset file

Per RESEARCH.md recommendations:
- Default reaction window: 2-15 seconds (chat lags behind speech)
- Topic proximity threshold: 30 seconds max
- Score candidates by proximity (closer = higher confidence)

In `src/alignment/window_aligner.py`:

```python
def align_chat_to_transcript(
    chat_messages: list[ChatMessage],
    transcript_segments: list["TranscriptSegment"],
    global_offset: float,
    reaction_window: tuple[float, float] = (2.0, 15.0),
    topic_proximity_threshold: float = 30.0,
) -> list[Alignment]:
    """
    Align chat messages to transcript segments with reaction lag.
    
    For each chat message:
    1. Adjust timestamp by global_offset
    2. Find transcript segments that could have triggered this chat
       (segment_end + reaction_window[0] <= chat_time <= segment_end + reaction_window[1])
    3. Filter by topic proximity (chat_time - segment_start <= threshold)
    4. Score by proximity and pick best match
    
    Returns: list of Alignment objects
    """
```

In `src/alignment/topic_matcher.py`:

```python
def filter_by_topic_proximity(
    candidates: list[dict],
    chat_time: float,
    threshold: float = 30.0,
) -> list[dict]:
    """
    Filter alignment candidates by temporal proximity.
    
    Removes candidates where chat_time is too far from segment start,
    preventing alignment of chat from much later in VOD to earlier transcript.
    """
```

Handle edge cases from CONTEXT.md:
- Silence periods → chat may not have matches, low confidence
- Overlapping speech → use segment that ends closest to chat time
- Missing chat segments → allow unmatched messages (not all chat aligns)
  </action>
  <verify>
```bash
python -c "
from src.alignment.window_aligner import align_chat_to_transcript
from src.alignment.topic_matcher import filter_by_topic_proximity
from src.alignment import ChatMessage
import inspect

# Check signatures
sig = inspect.signature(align_chat_to_transcript)
assert 'chat_messages' in sig.parameters
assert 'reaction_window' in sig.parameters
print('Window aligner signature OK')
"
```
  </verify>
  <done>
align_chat_to_transcript produces Alignment objects. Topic proximity filtering works. Chat messages with no good match get low confidence or are skipped.
  </done>
</task>

<task type="auto">
  <name>Task 4: Create phase 2 pipeline runner</name>
  <files>src/pipeline/__init__.py, src/pipeline/phase2_runner.py, src/__init__.py</files>
  <action>
Create CLI entry point that orchestrates transcription + alignment.

In `src/pipeline/phase2_runner.py`:

```python
from pathlib import Path
from src.transcription import transcribe_vod, write_all_outputs, TranscriptResult
from src.alignment import ChatMessage, AlignmentResult
from src.alignment.offset_detector import detect_chat_vod_offset
from src.alignment.window_aligner import align_chat_to_transcript

def run_phase2(
    audio_path: Path,
    chat_path: Path,  # JSON from Phase 1
    output_dir: Path,
    vod_id: str,
    model_size: str = "large-v3",
    device: str = "cuda",
    reaction_window: tuple[float, float] = (2.0, 15.0),
) -> AlignmentResult:
    """
    Run full Phase 2 pipeline: transcribe + align.
    
    Steps:
    1. Transcribe audio with WhisperX
    2. Load chat messages from Phase 1 JSON
    3. Detect global chat-VOD offset
    4. Align chat to transcript windows
    5. Write outputs (transcript JSON, SRT, metadata, alignment JSON)
    
    Returns: AlignmentResult with all alignment data
    """

def main():
    """CLI entry point for phase2 runner."""
    import argparse
    parser = argparse.ArgumentParser(description="Phase 2: Transcription & Alignment")
    parser.add_argument("--audio", required=True, help="Path to VOD audio file")
    parser.add_argument("--chat", required=True, help="Path to chat JSON from Phase 1")
    parser.add_argument("--output", required=True, help="Output directory")
    parser.add_argument("--vod-id", required=True, help="VOD identifier")
    parser.add_argument("--model", default="large-v3", help="Whisper model size")
    parser.add_argument("--device", default="cuda", help="Device (cuda/cpu)")
    args = parser.parse_args()
    
    result = run_phase2(
        audio_path=Path(args.audio),
        chat_path=Path(args.chat),
        output_dir=Path(args.output),
        vod_id=args.vod_id,
        model_size=args.model,
        device=args.device,
    )
    print(f"Aligned {len(result.alignments)} chat messages")
```

Also add `if __name__ == "__main__": main()` for direct execution.

In `src/pipeline/__init__.py`:
- Export: run_phase2

In `src/__init__.py`:
- Create minimal package init (can be empty or export key items)
  </action>
  <verify>
```bash
python -c "from src.pipeline import run_phase2" && echo "Pipeline imports OK"
python -m src.pipeline.phase2_runner --help
```
  </verify>
  <done>
CLI works. Can run `python -m src.pipeline.phase2_runner --help`. Pipeline orchestrates transcription + alignment.
  </done>
</task>

</tasks>

<verification>
1. Alignment models importable from src.alignment
2. offset_detector uses cross-correlation for auto detection
3. window_aligner accounts for reaction lag and topic proximity
4. Pipeline runner orchestrates full phase 2 flow
5. CLI accessible via python -m src.pipeline.phase2_runner
</verification>

<success_criteria>
- [ ] `from src.alignment import ChatMessage, Alignment, AlignmentResult` succeeds
- [ ] `detect_chat_vod_offset` returns float offset using cross-correlation
- [ ] `align_chat_to_transcript` produces Alignment objects with confidence scores
- [ ] `run_phase2` orchestrates transcription + alignment end-to-end
- [ ] CLI works: `python -m src.pipeline.phase2_runner --help`
- [ ] Alignment output stored in separate JSON file (not inline)
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcription-alignment/02-02-SUMMARY.md`
</output>
