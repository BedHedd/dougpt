---
phase: 02-local-speech-transcript-extraction
plan: 03
type: execute
wave: 2
depends_on:
  - "02-02"
files_modified:
  - 02-worktrees/asr-runner/pyproject.toml
  - 02-worktrees/asr-runner/asr_pipeline.py
autonomous: true
requirements:
  - ASR-02
  - ASR-03
issue:
  type: "dependency-compatibility"
  severity: "blocker"
  summary: "ctranslate2 requires CUDA, incompatible with AMD ROCm on NixOS"
must_haves:
  truths:
    - "User can run local ASR on AMD GPU without CUDA dependencies."
    - "Transcript exports stream to JSONL as segments are processed (resilient to long runs)."
  artifacts:
    - path: "02-worktrees/asr-runner/asr_pipeline.py"
      provides: "CLI to run Moonshine ASR with chunked streaming output"
      exports: ["--source-id", "--model", "--chunk-size", "--language"]
  key_decisions:
    - "Moonshine Voice selected over faster-whisper for AMD GPU support"
    - "ONNX runtime used instead of ctranslate2 (vendor-neutral)"
    - "Streaming JSONL output prevents data loss on long transcriptions"
---

<objective>
Swap faster-whisper (ctranslate2/CUDA) for moonshine-voice (ONNX) to enable AMD GPU acceleration on NixOS without CUDA dependencies.

Purpose: Resolve blocker where ctranslate2 requires CUDA, which is incompatible with AMD ROCm environment.
Output: Updated ASR pipeline using Moonshine with streaming JSONL output.
</objective>

<execution_context>
@/home/bedhedd/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/bedhedd/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<issue_analysis>

## Problem

When attempting to run the ASR pipeline with `faster-whisper`, the following error occurred:

```
AssertionError: 
CUDA driver version is insufficient for CUDA runtime version.
```

**Root Cause Analysis:**
1. `faster-whisper` depends on `ctranslate2`
2. `ctranslate2` from PyPI is built with CUDA support only
3. No ROCm-enabled `ctranslate2` wheels are available on the Anaconda ROCm index
4. User's system: NixOS with AMD Radeon RX 7900 XTX (ROCm 6.0, gfx1100)
5. Building `ctranslate2` from source with ROCm requires significant build infrastructure

**Environment Details:**
- GPU: AMD Radeon RX 7900 XTX (gfx1100)
- ROCm: Version 1.1 runtime, 1.14 ext
- OS: NixOS (Linux)
- CPU: AMD Ryzen 7 5800X3D

## Options Evaluated

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **whisper.cpp + Vulkan** | Native AMD support, mature, fast | C++ build, separate from Python pipeline | Considered |
| **Moonshine Voice** | Python-native, ONNX runtime, cross-vendor GPU, streaming | Newer project, English-focused models | **Selected** |
| **CPU-only ctranslate2** | Works without changes | Too slow for 4+ hour audio files | Rejected |
| **Build ctranslate2 with ROCm** | Keeps faster-whisper | Complex build, maintenance burden | Rejected |

## Decision: Moonshine Voice

**Why Moonshine:**
1. **ONNX Runtime** - Works with any GPU vendor (AMD, NVIDIA, Intel)
2. **Python-native** - No C++ build required, integrates with existing `uv` workflow
3. **Streaming support** - Better suited for long audio with incremental output
4. **Competitive accuracy** - Medium model achieves 6.65% WER vs Whisper Large-v3's 7.44%
5. **Smaller models** - 245M params vs 1.5B for Whisper Large-v3

**Trade-offs:**
- Currently supports 8 languages (en, es, ja, ko, vi, uk, zh, ar) vs Whisper's 99
- No built-in diarization (speaker labeling)
- No word-level timestamps in streaming mode

</issue_analysis>

<tasks>

<task type="auto">
  <name>Task 1: Replace faster-whisper with moonshine-voice</name>
  <files>02-worktrees/asr-runner/pyproject.toml</files>
  <action>Remove faster-whisper and ctranslate2 dependencies. Add moonshine-voice via `uv add moonshine-voice`. Update pyproject.toml description and remove CUDA/ROCm-specific comments.</action>
  <verify>
    <automated>cd 02-worktrees/asr-runner && uv run python -c "from moonshine_voice import Transcriber; print('moonshine loaded')"</automated>
  </verify>
  <done>Moonshine-voice installed and importable without CUDA dependencies.</done>
</task>

<task type="auto">
  <name>Task 2: Refactor ASR pipeline for Moonshine</name>
  <files>02-worktrees/asr-runner/asr_pipeline.py</files>
  <action>Rewrite asr_pipeline.py to use Moonshine API instead of faster-whisper. Key changes:
  - Use `Transcriber.transcribe_without_streaming()` for batch transcription
  - Implement chunked processing for long audio (configurable --chunk-size)
  - Add `StreamingJSONLWriter` class to write segments incrementally
  - Remove whisperX alignment and pyannote diarization code (not supported)
  - Update CLI options: remove --device, --compute-type, --skip-alignment, --skip-diarization
  - Add --chunk-size option for memory management
  - Add `download` command for Moonshine models</action>
  <verify>
    <automated>cd 02-worktrees/asr-runner && uv run python asr_pipeline.py --help</automated>
  </verify>
  <done>ASR pipeline runs Moonshine transcription with streaming JSONL output.</done>
</task>

<task type="auto">
  <name>Task 3: Download Moonshine model and test</name>
  <files></files>
  <action>Download English medium-streaming model via `uv run python -m moonshine_voice.download --language en`. Test transcription on prepared audio source.</action>
  <verify>
    <manual>Run: cd 02-worktrees/asr-runner && uv run python asr_pipeline.py transcribe --source-id "VpmmuHlLPM0" --model medium</manual>
  </verify>
  <done>Moonshine model downloaded and transcription runs successfully.</done>
</task>

</tasks>

<verification>
ASR CLI runs without CUDA errors. Transcription produces JSONL output with segments written incrementally during processing.
</verification>

<success_criteria>
- ASR pipeline runs locally on AMD GPU without CUDA dependencies
- JSONL exports stream to disk as segments are processed
- No assertion errors related to CUDA/ROCm driver mismatch
</success_criteria>

<output>
After completion, create `.planning/phases/02-local-speech-transcript-extraction/02-03-SUMMARY.md`.
</output>