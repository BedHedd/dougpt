---
phase: 02-chat-extraction-notebook-pipeline
plan: 02
type: execute
wave: 2
depends_on:
  - 02-01
files_modified:
  - 02-worktrees/chat-extraction/chat-extraction.py
  - 02-worktrees/chat-extraction/chat_pipeline.py
  - 00-supporting-files/data/chat-extraction/segments/
  - 00-supporting-files/data/chat-extraction/runs/
autonomous: true
requirements:
  - CHAT-03
must_haves:
  truths:
    - "User can run a local LLM stage to segment transcript content into chat-style blocks."
    - "Segment outputs are produced in both JSON and Markdown during the same run."
    - "Segments are chronological, include slight overlap, and include required fields id/start_time/end_time/speaker/summary."
  artifacts:
    - path: "02-worktrees/chat-extraction/chat_pipeline.py"
      provides: "Segmentation prompt, schema validation, overlap/chronology checks, and renderers"
      contains: "segment_transcript_with_local_llm"
    - path: "02-worktrees/chat-extraction/chat-extraction.py"
      provides: "Notebook cells for segmentation stage, review, reload, and export"
      contains: "segments.json + segments.md export"
    - path: "00-supporting-files/data/chat-extraction/segments"
      provides: "Final chat-style segmented artifacts"
      contains: "segments.json and segments.md"
  key_links:
    - from: "02-worktrees/chat-extraction/chat_pipeline.py"
      to: "http://localhost:1234/v1"
      via: "OpenAI-compatible local client call"
      pattern: "OpenAI\(base_url=\"http://localhost:1234/v1\""
    - from: "02-worktrees/chat-extraction/chat_pipeline.py"
      to: "00-dev-log/2026-02-09.md"
      via: "Style-target prompt constraints"
      pattern: "2026-02-09"
    - from: "02-worktrees/chat-extraction/chat-extraction.py"
      to: "00-supporting-files/data/chat-extraction/segments"
      via: "Export cell writes JSON and Markdown"
      pattern: "segments"
---

<objective>
Add the local LLM segmentation and export stages so transcript checkpoints become chronologically valid, chat-style artifacts in both machine and human-readable formats.

Purpose: Satisfies CHAT-03 while preserving reliability through strict schema validation, chronology checks, and deterministic output rendering.
Output: Local LLM segmentation notebook flow producing `segments.json`, `segments.md`, and run metadata links.
</objective>

<execution_context>
@/home/bedhedd/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/bedhedd/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-chat-extraction-notebook-pipeline/02-CONTEXT.md
@.planning/phases/02-chat-extraction-notebook-pipeline/02-RESEARCH.md
@.planning/phases/02-chat-extraction-notebook-pipeline/02-01-SUMMARY.md
@00-dev-log/2026-02-09.md
@02-worktrees/chat-extraction/chat-extraction.py
@02-worktrees/chat-extraction/chat_pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement schema-constrained local LLM segmentation stage</name>
  <files>02-worktrees/chat-extraction/chat_pipeline.py, 02-worktrees/chat-extraction/chat-extraction.py</files>
  <action>Add segmentation helpers that read transcript checkpoint JSON and call a local OpenAI-compatible endpoint (LM Studio-style `base_url=http://localhost:1234/v1`) using strict JSON-schema response format. Enforce required output fields `id`, `start_time`, `end_time`, `speaker`, `summary`; add post-validation for chronological ordering and slight overlap between adjacent segments. Keep segmentation hybrid (semantic/topic-aware within time-window constraints), and include explicit style guidance aligned with `00-dev-log/2026-02-09.md` while keeping output mostly faithful to transcript content.</action>
  <verify>From `02-worktrees/chat-extraction`, run `uv run python -c "import chat_pipeline as cp; print(hasattr(cp, 'segment_transcript_with_local_llm'))"` and execute notebook segmentation on one transcript artifact to confirm parsed segments pass schema validation.</verify>
  <done>Notebook can generate validated chat-style segments from transcript artifacts with required fields, chronology, and overlap constraints enforced.</done>
</task>

<task type="auto">
  <name>Task 2: Render unified segment objects into JSON and Markdown outputs</name>
  <files>02-worktrees/chat-extraction/chat_pipeline.py, 02-worktrees/chat-extraction/chat-extraction.py</files>
  <action>Create deterministic renderers that write both `segments.json` and `segments.md` from the same normalized segment objects in a single run. Ensure markdown format is review-friendly for human editing and that notebook cells can reload edited `.json`/`.md` outputs back into in-memory structures without manual reformatting. Do not introduce transcript/chat direct alignment features beyond transcript-based segmentation (deferred scope).</action>
  <verify>Run notebook export for one transcript and confirm both files are written in `00-supporting-files/data/chat-extraction/segments/`; reload each file in notebook and confirm parsed segment count and IDs match.</verify>
  <done>Single segmentation run writes JSON and Markdown outputs that are mutually consistent and reload-safe for iterative edits.</done>
</task>

<task type="auto">
  <name>Task 3: Add end-to-end notebook pipeline run cell and smoke verification hooks</name>
  <files>02-worktrees/chat-extraction/chat-extraction.py, 00-supporting-files/data/chat-extraction/runs/</files>
  <action>Add a final notebook orchestration cell that executes extraction/transcription/segmentation in order using checkpoint reuse from Plan 01, then emits artifact paths and run summary metadata. Include a lightweight schema-conformance smoke check for local segmentation model availability before running full batch segmentation; if unavailable, fail early with actionable guidance while preserving prior artifacts.</action>
  <verify>Execute the end-to-end notebook flow on the canonical sample video and confirm `audio`, `transcripts`, `segments/segments.json`, and `segments/segments.md` exist with run metadata linking all stages.</verify>
  <done>User can run one local notebook workflow end-to-end without hosted APIs and receives linked stage artifacts plus validated final segmented outputs.</done>
</task>

</tasks>

<verification>
Run one end-to-end local notebook execution and verify final outputs include valid segmented JSON/Markdown files aligned to transcript checkpoints, with chronology/overlap checks passing and run metadata capturing local model configuration.
</verification>

<success_criteria>
`CHAT-03` is satisfied: a local LLM segmentation pass converts transcript content into chat-style segment blocks aligned with `00-dev-log/2026-02-09.md` style and exports synchronized JSON+Markdown artifacts in one run.
</success_criteria>

<output>
After completion, create `.planning/phases/02-chat-extraction-notebook-pipeline/02-02-SUMMARY.md`
</output>
