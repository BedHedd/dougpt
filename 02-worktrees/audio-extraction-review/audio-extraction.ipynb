{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Extraction Review Pipeline\n",
        "\n",
        "Stage 1: deterministic input discovery and ffmpeg extraction with batch-safe failure logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import json, shlex, subprocess, time\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from typing import Any\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG: dict[str, Any] = {\n",
        "    \"input_mode\": \"single\",\n",
        "    \"single_input\": \"large-files/Doug and Twitch Chat TAKE OVER EUROPE-VpmmuHlLPM0.mkv\",\n",
        "    \"batch_inputs\": [],\n",
        "    \"batch_glob\": \"*.mkv\",\n",
        "    \"force_reextract\": False,\n",
        "    \"ffmpeg\": {\"audio_codec\": \"flac\", \"sample_rate\": 16000, \"channels\": 1, \"overwrite\": True},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def now_iso() -> str:\n",
        "    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")\n",
        "\n",
        "def resolve_project_paths(start: Path | None = None) -> dict[str, Path]:\n",
        "    start_path = (start or Path.cwd()).resolve()\n",
        "    candidates = [start_path, *start_path.parents]\n",
        "    anchor = next((p / \"00-supporting-files\" for p in candidates if (p / \"00-supporting-files\").exists()), None)\n",
        "    if anchor is None:\n",
        "        raise FileNotFoundError(\"Could not locate 00-supporting-files anchor\")\n",
        "    project_root = anchor.parent\n",
        "    data_root = anchor / \"data\" / \"audio-extraction-review\"\n",
        "    paths = {\n",
        "        \"project_root\": project_root,\n",
        "        \"supporting_files\": anchor,\n",
        "        \"data_root\": data_root,\n",
        "        \"audio_dir\": data_root / \"audio\",\n",
        "        \"logs_dir\": data_root / \"logs\",\n",
        "        \"runs_dir\": data_root / \"runs\",\n",
        "    }\n",
        "    for key in (\"data_root\", \"audio_dir\", \"logs_dir\", \"runs_dir\"):\n",
        "        paths[key].mkdir(parents=True, exist_ok=True)\n",
        "    return paths\n",
        "\n",
        "def as_project_relative(path: Path, project_root: Path) -> str:\n",
        "    try:\n",
        "        return str(path.resolve().relative_to(project_root))\n",
        "    except Exception:\n",
        "        return str(path.resolve())\n",
        "\n",
        "def discover_inputs(config: dict[str, Any], project_root: Path) -> list[Path]:\n",
        "    mode = config[\"input_mode\"].strip().lower()\n",
        "    if mode == \"single\":\n",
        "        p = Path(config[\"single_input\"])\n",
        "        if not p.is_absolute():\n",
        "            p = (project_root / p).resolve()\n",
        "        return [p]\n",
        "    if mode == \"batch\":\n",
        "        items: list[Path] = []\n",
        "        for raw in config.get(\"batch_inputs\", []):\n",
        "            p = Path(raw)\n",
        "            if not p.is_absolute():\n",
        "                p = (project_root / p).resolve()\n",
        "            items.append(p)\n",
        "        glob_pattern = config.get(\"batch_glob\")\n",
        "        if glob_pattern:\n",
        "            large_files_dir = project_root / \"large-files\"\n",
        "            if large_files_dir.exists():\n",
        "                items.extend(sorted(large_files_dir.glob(glob_pattern)))\n",
        "        return sorted({p.resolve() for p in items})\n",
        "    raise ValueError(\"input_mode must be single or batch\")\n",
        "\n",
        "def append_jsonl(path: Path, payload: dict[str, Any]) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open(\"a\", encoding=\"utf-8\") as fh:\n",
        "        fh.write(json.dumps(payload, ensure_ascii=True) + \"\\n\")\n",
        "\n",
        "def output_audio_path(input_media: Path, audio_dir: Path) -> Path:\n",
        "    return audio_dir / f\"{input_media.stem.replace(' ', '_')}.flac\"\n",
        "\n",
        "def ffprobe_duration_seconds(path: Path) -> float | None:\n",
        "    cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", str(path)]\n",
        "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    if proc.returncode != 0:\n",
        "        return None\n",
        "    try:\n",
        "        return float(proc.stdout.strip()) if proc.stdout.strip() else None\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "def extract_audio(input_media: Path, output_audio: Path, ffmpeg_cfg: dict[str, Any]) -> subprocess.CompletedProcess[str]:\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-v\", \"error\", \"-y\" if ffmpeg_cfg.get(\"overwrite\", True) else \"-n\", \"-i\", str(input_media),\n",
        "        \"-vn\", \"-ac\", str(ffmpeg_cfg.get(\"channels\", 1)), \"-ar\", str(ffmpeg_cfg.get(\"sample_rate\", 16000)),\n",
        "        \"-c:a\", str(ffmpeg_cfg.get(\"audio_codec\", \"flac\")), str(output_audio),\n",
        "    ]\n",
        "    return subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "def run_extraction_stage(*, inputs: list[Path], paths: dict[str, Path], config: dict[str, Any], run_id: str) -> dict[str, Any]:\n",
        "    started = time.perf_counter()\n",
        "    run_log = paths[\"logs_dir\"] / f\"extraction-{run_id}.jsonl\"\n",
        "    failure_log = paths[\"logs_dir\"] / \"extraction-failures.jsonl\"\n",
        "    records: list[dict[str, Any]] = []\n",
        "    failures: list[dict[str, Any]] = []\n",
        "\n",
        "    for input_media in inputs:\n",
        "        record = {\"run_id\": run_id, \"timestamp\": now_iso(), \"stage\": \"extract\", \"input_media\": str(input_media), \"status\": \"pending\"}\n",
        "        if not input_media.exists():\n",
        "            record.update({\"status\": \"failed\", \"error\": \"input_not_found\"})\n",
        "            append_jsonl(run_log, record)\n",
        "            append_jsonl(failure_log, record)\n",
        "            records.append(record)\n",
        "            failures.append(record)\n",
        "            continue\n",
        "\n",
        "        out_audio = output_audio_path(input_media, paths[\"audio_dir\"])\n",
        "        if out_audio.exists() and not config.get(\"force_reextract\", False):\n",
        "            record.update({\"status\": \"reused\", \"audio_path\": str(out_audio), \"resume_marker\": True})\n",
        "            append_jsonl(run_log, record)\n",
        "            records.append(record)\n",
        "            continue\n",
        "\n",
        "        proc = extract_audio(input_media, out_audio, config[\"ffmpeg\"])\n",
        "        if proc.returncode != 0:\n",
        "            record.update({\"status\": \"failed\", \"error\": \"ffmpeg_failed\", \"stderr\": proc.stderr.strip(), \"command\": \" \".join(shlex.quote(p) for p in proc.args)})\n",
        "            append_jsonl(run_log, record)\n",
        "            append_jsonl(failure_log, record)\n",
        "            records.append(record)\n",
        "            failures.append(record)\n",
        "            continue\n",
        "\n",
        "        record.update({\"status\": \"ok\", \"audio_path\": str(out_audio), \"audio_duration_seconds\": ffprobe_duration_seconds(out_audio), \"resume_marker\": False})\n",
        "        append_jsonl(run_log, record)\n",
        "        records.append(record)\n",
        "\n",
        "    return {\n",
        "        \"stage\": \"extract\",\n",
        "        \"duration_seconds\": round(time.perf_counter() - started, 3),\n",
        "        \"records\": records,\n",
        "        \"failures\": failures,\n",
        "        \"log_path\": str(run_log),\n",
        "        \"failure_log_path\": str(failure_log),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "paths = resolve_project_paths()\n",
        "{key: as_project_relative(value, paths[\"project_root\"]) for key, value in paths.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example:\n",
        "# inputs = discover_inputs(CONFIG, paths[\"project_root\"])\n",
        "# extraction = run_extraction_stage(inputs=inputs, paths=paths, config=CONFIG, run_id=\"manual-run\")\n",
        "# extraction\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
