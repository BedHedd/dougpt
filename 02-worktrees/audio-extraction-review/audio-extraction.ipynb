{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Extraction Review Pipeline\n",
        "\n",
        "Stages 1-2: extraction plus local Whisper transcription with reusable JSON transcripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import json, os, shlex, subprocess, time, traceback\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from typing import Any\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG: dict[str, Any] = {\n",
        "    \"input_mode\": \"single\",\n",
        "    \"single_input\": \"large-files/Doug and Twitch Chat TAKE OVER EUROPE-VpmmuHlLPM0.mkv\",\n",
        "    \"batch_inputs\": [],\n",
        "    \"batch_glob\": \"*.mkv\",\n",
        "    \"force_reextract\": False,\n",
        "    \"force_retranscribe\": False,\n",
        "    \"ffmpeg\": {\"audio_codec\": \"flac\", \"sample_rate\": 16000, \"channels\": 1, \"overwrite\": True},\n",
        "    \"transcription\": {\n",
        "        \"model_name\": \"tiny.en\",\n",
        "        \"device\": \"cpu\",\n",
        "        \"compute_type\": \"int8\",\n",
        "        \"beam_size\": 5,\n",
        "        \"vad_filter\": True,\n",
        "        \"word_timestamps\": True,\n",
        "    },\n",
        "    \"diarization\": {\n",
        "        \"enabled\": True,\n",
        "        \"provider\": \"whisperx\",\n",
        "        \"device\": \"cpu\",\n",
        "        \"min_overlap_seconds\": 0.2,\n",
        "    },\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def now_iso() -> str:\n",
        "    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")\n",
        "\n",
        "def resolve_project_paths(start: Path | None = None) -> dict[str, Path]:\n",
        "    start_path = (start or Path.cwd()).resolve()\n",
        "    candidates = [start_path, *start_path.parents]\n",
        "    anchor = next((p / \"00-supporting-files\" for p in candidates if (p / \"00-supporting-files\").exists()), None)\n",
        "    if anchor is None:\n",
        "        raise FileNotFoundError(\"Could not locate 00-supporting-files anchor\")\n",
        "    project_root = anchor.parent\n",
        "    data_root = anchor / \"data\" / \"audio-extraction-review\"\n",
        "    paths = {\n",
        "        \"project_root\": project_root,\n",
        "        \"supporting_files\": anchor,\n",
        "        \"data_root\": data_root,\n",
        "        \"audio_dir\": data_root / \"audio\",\n",
        "        \"logs_dir\": data_root / \"logs\",\n",
        "        \"runs_dir\": data_root / \"runs\",\n",
        "        \"transcripts_dir\": data_root / \"transcripts\",\n",
        "    }\n",
        "    for key in (\"data_root\", \"audio_dir\", \"logs_dir\", \"runs_dir\", \"transcripts_dir\"):\n",
        "        paths[key].mkdir(parents=True, exist_ok=True)\n",
        "    return paths\n",
        "\n",
        "def as_project_relative(path: Path, project_root: Path) -> str:\n",
        "    try:\n",
        "        return str(path.resolve().relative_to(project_root))\n",
        "    except Exception:\n",
        "        return str(path.resolve())\n",
        "\n",
        "def discover_inputs(config: dict[str, Any], project_root: Path) -> list[Path]:\n",
        "    mode = config[\"input_mode\"].strip().lower()\n",
        "    if mode == \"single\":\n",
        "        p = Path(config[\"single_input\"])\n",
        "        if not p.is_absolute():\n",
        "            p = (project_root / p).resolve()\n",
        "        return [p]\n",
        "    if mode == \"batch\":\n",
        "        items: list[Path] = []\n",
        "        for raw in config.get(\"batch_inputs\", []):\n",
        "            p = Path(raw)\n",
        "            if not p.is_absolute():\n",
        "                p = (project_root / p).resolve()\n",
        "            items.append(p)\n",
        "        glob_pattern = config.get(\"batch_glob\")\n",
        "        if glob_pattern:\n",
        "            large_files_dir = project_root / \"large-files\"\n",
        "            if large_files_dir.exists():\n",
        "                items.extend(sorted(large_files_dir.glob(glob_pattern)))\n",
        "        return sorted({p.resolve() for p in items})\n",
        "    raise ValueError(\"input_mode must be single or batch\")\n",
        "\n",
        "def append_jsonl(path: Path, payload: dict[str, Any]) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open(\"a\", encoding=\"utf-8\") as fh:\n",
        "        fh.write(json.dumps(payload, ensure_ascii=True) + \"\\n\")\n",
        "\n",
        "def output_audio_path(input_media: Path, audio_dir: Path) -> Path:\n",
        "    return audio_dir / f\"{input_media.stem.replace(' ', '_')}.flac\"\n",
        "\n",
        "def ffprobe_duration_seconds(path: Path) -> float | None:\n",
        "    cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", str(path)]\n",
        "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    if proc.returncode != 0:\n",
        "        return None\n",
        "    try:\n",
        "        return float(proc.stdout.strip()) if proc.stdout.strip() else None\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "def extract_audio(input_media: Path, output_audio: Path, ffmpeg_cfg: dict[str, Any]) -> subprocess.CompletedProcess[str]:\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-v\", \"error\", \"-y\" if ffmpeg_cfg.get(\"overwrite\", True) else \"-n\", \"-i\", str(input_media),\n",
        "        \"-vn\", \"-ac\", str(ffmpeg_cfg.get(\"channels\", 1)), \"-ar\", str(ffmpeg_cfg.get(\"sample_rate\", 16000)),\n",
        "        \"-c:a\", str(ffmpeg_cfg.get(\"audio_codec\", \"flac\")), str(output_audio),\n",
        "    ]\n",
        "    return subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "def run_extraction_stage(*, inputs: list[Path], paths: dict[str, Path], config: dict[str, Any], run_id: str) -> dict[str, Any]:\n",
        "    started = time.perf_counter()\n",
        "    run_log = paths[\"logs_dir\"] / f\"extraction-{run_id}.jsonl\"\n",
        "    failure_log = paths[\"logs_dir\"] / \"extraction-failures.jsonl\"\n",
        "    records: list[dict[str, Any]] = []\n",
        "    failures: list[dict[str, Any]] = []\n",
        "\n",
        "    for input_media in inputs:\n",
        "        record = {\"run_id\": run_id, \"timestamp\": now_iso(), \"stage\": \"extract\", \"input_media\": str(input_media), \"status\": \"pending\"}\n",
        "        if not input_media.exists():\n",
        "            record.update({\"status\": \"failed\", \"error\": \"input_not_found\"})\n",
        "            append_jsonl(run_log, record)\n",
        "            append_jsonl(failure_log, record)\n",
        "            records.append(record)\n",
        "            failures.append(record)\n",
        "            continue\n",
        "\n",
        "        out_audio = output_audio_path(input_media, paths[\"audio_dir\"])\n",
        "        if out_audio.exists() and not config.get(\"force_reextract\", False):\n",
        "            record.update({\"status\": \"reused\", \"audio_path\": str(out_audio), \"resume_marker\": True})\n",
        "            append_jsonl(run_log, record)\n",
        "            records.append(record)\n",
        "            continue\n",
        "\n",
        "        proc = extract_audio(input_media, out_audio, config[\"ffmpeg\"])\n",
        "        if proc.returncode != 0:\n",
        "            record.update({\"status\": \"failed\", \"error\": \"ffmpeg_failed\", \"stderr\": proc.stderr.strip(), \"command\": \" \".join(shlex.quote(p) for p in proc.args)})\n",
        "            append_jsonl(run_log, record)\n",
        "            append_jsonl(failure_log, record)\n",
        "            records.append(record)\n",
        "            failures.append(record)\n",
        "            continue\n",
        "\n",
        "        record.update({\"status\": \"ok\", \"audio_path\": str(out_audio), \"audio_duration_seconds\": ffprobe_duration_seconds(out_audio), \"resume_marker\": False})\n",
        "        append_jsonl(run_log, record)\n",
        "        records.append(record)\n",
        "\n",
        "    return {\n",
        "        \"stage\": \"extract\",\n",
        "        \"duration_seconds\": round(time.perf_counter() - started, 3),\n",
        "        \"records\": records,\n",
        "        \"failures\": failures,\n",
        "        \"log_path\": str(run_log),\n",
        "        \"failure_log_path\": str(failure_log),\n",
        "    }\n",
        "\n",
        "def _segment_overlap_seconds(segment_start: float, segment_end: float, diar_start: float, diar_end: float) -> float:\n",
        "    return max(0.0, min(segment_end, diar_end) - max(segment_start, diar_start))\n",
        "\n",
        "def best_effort_diarization(*, audio_path: Path, config: dict[str, Any]) -> tuple[list[dict[str, Any]], dict[str, Any]]:\n",
        "    diar_cfg = config.get(\"diarization\", {})\n",
        "    if not diar_cfg.get(\"enabled\", True):\n",
        "        return [], {\"attempted\": False, \"provider\": diar_cfg.get(\"provider\", \"whisperx\"), \"used\": False, \"fallback_reason\": \"disabled_in_config\"}\n",
        "\n",
        "    token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "    if not token:\n",
        "        return [], {\"attempted\": True, \"provider\": diar_cfg.get(\"provider\", \"whisperx\"), \"used\": False, \"fallback_reason\": \"missing_huggingface_token\"}\n",
        "\n",
        "    try:\n",
        "        import whisperx\n",
        "        from whisperx.diarize import DiarizationPipeline\n",
        "    except Exception:\n",
        "        return [], {\"attempted\": True, \"provider\": diar_cfg.get(\"provider\", \"whisperx\"), \"used\": False, \"fallback_reason\": \"whisperx_or_pyannote_not_installed\"}\n",
        "\n",
        "    try:\n",
        "        audio = whisperx.load_audio(str(audio_path))\n",
        "        diarize_model = DiarizationPipeline(token=token, device=diar_cfg.get(\"device\", \"cpu\"))\n",
        "        diar_df = diarize_model(audio)\n",
        "        diar_segments = [{\"start\": float(r[\"start\"]), \"end\": float(r[\"end\"]), \"speaker\": str(r[\"speaker\"])} for _, r in diar_df.iterrows()]\n",
        "        return diar_segments, {\"attempted\": True, \"provider\": diar_cfg.get(\"provider\", \"whisperx\"), \"used\": True, \"fallback_reason\": None}\n",
        "    except Exception as exc:\n",
        "        return [], {\"attempted\": True, \"provider\": diar_cfg.get(\"provider\", \"whisperx\"), \"used\": False, \"fallback_reason\": f\"diarization_failed: {exc}\"}\n",
        "\n",
        "def pick_segment_speaker(*, segment_start: float, segment_end: float, diar_segments: list[dict[str, Any]], min_overlap_seconds: float) -> str:\n",
        "    best: tuple[float, str] | None = None\n",
        "    for diar in diar_segments:\n",
        "        overlap = _segment_overlap_seconds(segment_start, segment_end, diar[\"start\"], diar[\"end\"])\n",
        "        if overlap <= 0:\n",
        "            continue\n",
        "        if best is None or overlap > best[0]:\n",
        "            best = (overlap, diar[\"speaker\"])\n",
        "    if best is None or best[0] < min_overlap_seconds:\n",
        "        return \"UNKNOWN\"\n",
        "    return best[1]\n",
        "\n",
        "def transcribe_audio_with_faster_whisper(audio_path: Path, config: dict[str, Any]) -> tuple[list[dict[str, Any]], dict[str, Any]]:\n",
        "    try:\n",
        "        from faster_whisper import WhisperModel\n",
        "    except Exception as exc:\n",
        "        raise RuntimeError(\"faster_whisper_not_installed\") from exc\n",
        "\n",
        "    tcfg = config[\"transcription\"]\n",
        "    model = WhisperModel(tcfg.get(\"model_name\", \"tiny.en\"), device=tcfg.get(\"device\", \"cpu\"), compute_type=tcfg.get(\"compute_type\", \"int8\"))\n",
        "    seg_iter, info = model.transcribe(str(audio_path), beam_size=tcfg.get(\"beam_size\", 5), vad_filter=tcfg.get(\"vad_filter\", True), word_timestamps=tcfg.get(\"word_timestamps\", True))\n",
        "\n",
        "    segments = []\n",
        "    for idx, seg in enumerate(seg_iter, start=1):\n",
        "        words = []\n",
        "        for w in (seg.words or []):\n",
        "            words.append({\"start\": float(w.start), \"end\": float(w.end), \"word\": w.word, \"probability\": float(w.probability)})\n",
        "        segments.append({\"id\": idx, \"start\": float(seg.start), \"end\": float(seg.end), \"text\": seg.text.strip(), \"words\": words})\n",
        "\n",
        "    info_payload = {\n",
        "        \"language\": getattr(info, \"language\", None),\n",
        "        \"language_probability\": float(getattr(info, \"language_probability\", 0.0) or 0.0),\n",
        "        \"duration\": float(getattr(info, \"duration\", 0.0) or 0.0),\n",
        "        \"duration_after_vad\": float(getattr(info, \"duration_after_vad\", 0.0) or 0.0),\n",
        "    }\n",
        "    return segments, info_payload\n",
        "\n",
        "def transcript_output_path(audio_path: Path, transcripts_dir: Path) -> Path:\n",
        "    return transcripts_dir / f\"{audio_path.stem}.json\"\n",
        "\n",
        "def run_transcription_stage(*, extraction_records: list[dict[str, Any]], paths: dict[str, Path], config: dict[str, Any], run_id: str) -> dict[str, Any]:\n",
        "    started = time.perf_counter()\n",
        "    run_log = paths[\"logs_dir\"] / f\"transcription-{run_id}.jsonl\"\n",
        "    records: list[dict[str, Any]] = []\n",
        "    failures: list[dict[str, Any]] = []\n",
        "\n",
        "    for item in extraction_records:\n",
        "        if item.get(\"status\") not in {\"ok\", \"reused\"}:\n",
        "            continue\n",
        "\n",
        "        audio_path = Path(item[\"audio_path\"])\n",
        "        transcript_path = transcript_output_path(audio_path, paths[\"transcripts_dir\"])\n",
        "        record = {\n",
        "            \"run_id\": run_id,\n",
        "            \"timestamp\": now_iso(),\n",
        "            \"stage\": \"transcribe\",\n",
        "            \"audio_path\": str(audio_path),\n",
        "            \"transcript_path\": str(transcript_path),\n",
        "            \"status\": \"pending\",\n",
        "        }\n",
        "\n",
        "        if transcript_path.exists() and not config.get(\"force_retranscribe\", False):\n",
        "            record.update({\"status\": \"reused\", \"resume_marker\": True})\n",
        "            append_jsonl(run_log, record)\n",
        "            records.append(record)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            segments, info_payload = transcribe_audio_with_faster_whisper(audio_path, config)\n",
        "            diar_segments, diar_meta = best_effort_diarization(audio_path=audio_path, config=config)\n",
        "            min_overlap = float(config.get(\"diarization\", {}).get(\"min_overlap_seconds\", 0.2))\n",
        "\n",
        "            normalized = []\n",
        "            for seg in segments:\n",
        "                normalized.append({\n",
        "                    \"id\": seg[\"id\"],\n",
        "                    \"start\": seg[\"start\"],\n",
        "                    \"end\": seg[\"end\"],\n",
        "                    \"speaker\": pick_segment_speaker(segment_start=seg[\"start\"], segment_end=seg[\"end\"], diar_segments=diar_segments, min_overlap_seconds=min_overlap),\n",
        "                    \"text\": seg[\"text\"],\n",
        "                    \"words\": seg[\"words\"],\n",
        "                })\n",
        "\n",
        "            payload = {\n",
        "                \"schema_version\": \"1.0\",\n",
        "                \"run_id\": run_id,\n",
        "                \"created_at\": now_iso(),\n",
        "                \"source\": {\n",
        "                    \"media_path\": item.get(\"input_media\"),\n",
        "                    \"audio_path\": str(audio_path),\n",
        "                    \"audio_duration_seconds\": ffprobe_duration_seconds(audio_path),\n",
        "                },\n",
        "                \"transcription\": {\n",
        "                    \"engine\": \"faster-whisper\",\n",
        "                    \"model_name\": config[\"transcription\"].get(\"model_name\"),\n",
        "                    \"device\": config[\"transcription\"].get(\"device\"),\n",
        "                    \"compute_type\": config[\"transcription\"].get(\"compute_type\"),\n",
        "                    \"language\": info_payload.get(\"language\"),\n",
        "                    \"language_probability\": info_payload.get(\"language_probability\"),\n",
        "                    \"duration_seconds\": info_payload.get(\"duration\"),\n",
        "                    \"duration_after_vad_seconds\": info_payload.get(\"duration_after_vad\"),\n",
        "                },\n",
        "                \"diarization\": diar_meta,\n",
        "                \"segments\": normalized,\n",
        "            }\n",
        "            transcript_path.write_text(json.dumps(payload, indent=2, ensure_ascii=True), encoding=\"utf-8\")\n",
        "\n",
        "            record.update({\n",
        "                \"status\": \"ok\",\n",
        "                \"segment_count\": len(normalized),\n",
        "                \"word_timestamp_count\": sum(len(s[\"words\"]) for s in normalized),\n",
        "                \"resume_marker\": False,\n",
        "                \"diarization_fallback_reason\": diar_meta.get(\"fallback_reason\"),\n",
        "            })\n",
        "            append_jsonl(run_log, record)\n",
        "            records.append(record)\n",
        "        except Exception as exc:\n",
        "            record.update({\"status\": \"failed\", \"error\": str(exc), \"traceback\": traceback.format_exc()})\n",
        "            append_jsonl(run_log, record)\n",
        "            records.append(record)\n",
        "            failures.append(record)\n",
        "\n",
        "    return {\n",
        "        \"stage\": \"transcribe\",\n",
        "        \"duration_seconds\": round(time.perf_counter() - started, 3),\n",
        "        \"records\": records,\n",
        "        \"failures\": failures,\n",
        "        \"log_path\": str(run_log),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "paths = resolve_project_paths()\n",
        "{key: as_project_relative(value, paths[\"project_root\"]) for key, value in paths.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example:\n",
        "# inputs = discover_inputs(CONFIG, paths[\"project_root\"])\n",
        "# extraction = run_extraction_stage(inputs=inputs, paths=paths, config=CONFIG, run_id=\"manual-run\")\n",
        "# transcription = run_transcription_stage(extraction_records=extraction[\"records\"], paths=paths, config=CONFIG, run_id=\"manual-run\")\n",
        "# transcription\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
